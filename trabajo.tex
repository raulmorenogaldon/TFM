\chapter{Trabajo de investigación: Recalibrador de altas prestaciones usando para\-lelismo}

En este capitulo se detalla el trabajo llevado a cabo durante la realización del máster. Se presentara el ámbito en el que se ha trabajado, desde donde se ha partido y cuales han sido los pasos seguidos hasta llegar al final de este trabajo. Básicamente el objetivo del trabajo era conseguir un software recalibrador acelerado, usando técnicas de optimización y paralelismo que fuesen más eficientes y rápidas que las utilizadas por el de referencia.\\

Primeramente se describirá en que consiste el proceso de descubrimiento de variantes, qué función tiene un recalibrador en ese proceso, pasando seguidamente a lo que se ha realizado a partir de ahí y qué pasos se han seguido. Se hará una descripción del algoritmo implementado y sus estructuras de datos, haciendo finalmente una evaluación de rendimiento.\\

\section{Introducción al descubrimiento de variantes}

\subsection{Introducción al ADN}

El \textit{ADN} \cite{molecularbio} (ácido desoxirribonucleico) contiene las instrucciones genéticas usadas en el desarrollo y funcionamiento de todos los organismos vivos conocidos y algunos virus, y es responsable de su transmisión hereditaria. Se puede comparar el ADN con una receta o código, ya que a partir del mismo se obtienen las instrucciones necesarias para construir las células. Los segmentos de ADN que contienen esta información son los denominados genes, mientras que el resto de secuencias tienen propósitos estructurales y reguladores en el uso de esta información. En la Figura \ref{fig:adn} tenemos la representación gráfica que muestra dónde reside el ADN.\\

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{adn.png}
\caption{¿Dónde se encuentra el ADN?.\label{fig:adn}}
\end{figure} 

El ADN es un polímero de nucleótidos, está formado por muchas unidades simples (nucleótidos) conectadas entre sí (Figura \ref{fig:adnquimic}). Los nucleótidos están formados por un azúcar, una base nitrogenada (pueden ser Adenina, Timina, Citosina y Guanina) y un grupo fosfato para interconectarlos. Puesto que lo único que distingue a un nucleótido de otro es la base nitrogenada, la secuencia de ADN se representa por una secuencia de estas bases. En estas secuencias cada base se representa por su inicial, por lo que tienen una representación del tipo \textit{AGTCTAGATCG}\ldots En los organismos vivos el ADN se presenta como una doble cadena de nucleótidos.\\

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{adnquimic.png}
\caption{Representación química del ADN.\label{fig:adnquimic}}
\end{figure} 

Como ya se ha dicho, un gen es una secuencia del ADN que contiene información genética. Un gen es una unidad de herencia que influye en una característica particular de un organismo (como el color de los ojos, por ejemplo). A partir de los genes se producen las proteínas del organismo, que son las encargadas de generar los músculos, pelo, enzimas\ldots\\

\subsection{Descripción del proceso de descu\-bri\-mien\-to de variantes}

Puesto que un cambio en el ADN puede traducirse en un cambio brusco de las proteínas que genera el organismo, esto puede dar lugar a trastornos, enfermedades, etc. El proceso de descubrimiento de variantes tiene como objetivo localizar variaciones, mutaciones o \textit{indels} (\textit{insertions/deletions}) en una muestra de ADN con respecto a otra, por ejemplo para poder determinar la causa de enfermedades o prevenirlas.\\

Un ejemplo sería analizar el ADN de una población (conjunto de individuos) que tengan un determinado tipo de cáncer y otra población que no lo tengan. Estos individuos tendrán muchas similitudes en el ADN puesto que pertenecen a la misma especie, pero también diferirán en otras. Cuando encontremos la secuencia de ADN común a la población con cáncer pero que no aparezca en la población sin cáncer, tendremos la razón de ese cáncer localizada y podremos tratarlo y prevenirlo.\\

El proceso de descubrimiento de variantes tiene tres fases. En la primera fase se obtienen lecturas de ADN en un formato específico y dependiente de la plataforma que las haya obtenido. Lo que se hace con estas lecturas es transformarlas a un único formato genérico, con unas calidades bien calibradas, mapeadas y alineadas con su ADN de referencia. El formato utilizado es el \textit{SAM/BAM} \cite{bamsam} (\textit{Sequence Aligment Map/Binary Alignment Map}), el cual es independiente de la tecnología de obtención del ADN.\\

En la segunda fase se analizan los ficheros \textit{SAM/BAM} para obtener posiciones del ADN que, según evidencia estadística, sean mutaciones respecto al ADN de referencia. Esto incluye diferencias en una sola posición de la cadena de ADN (\textit{SNP}), pequeños \textit{indels}, etc.\\

En la última fase se analizan las mutaciones obtenidas y la estructura del ADN para tomar conclusiones. En la Figura \ref{fig:procesodescubrimiento} se puede ver gráficamente estas tres fases.\\

\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{variationdiscover.jpg}
\caption{Proceso de descubrimiento de variantes en el ADN.\label{fig:procesodescubrimiento}}
\end{figure} 

\subsection{Descripción de un recalibrador}

El ADN se obtiene mediante máquinas de propósito específico llamadas secuenciadores. Se basan en técnicas bioquímicas cuya finalidad es la determinación del orden de los nucleótidos en la secuencia de ADN. Hay distintos factores que influyen en la toma de lecturas del ADN, que pueden llevar a errores. Estos factores se expresan mediante una calidad de error que el secuenciador asigna a cada lectura, en el momento de tomarla, dependiendo de qué posibilidad hay de que sea errónea.\\

La probabilidad de que una lectura sea errónea se mapea en un rango de enteros, denominado calidad \textit{Sanger} \cite{sanger}. Para ello se aplica la fórmula \begin{equation}
Q = -10*\log_{10} P
\end{equation} 
cuya entrada es un rango de números reales [0,1] y su salida en el rango de número naturales positivos [0,93] (acotado superiormente). La razón de utilizar esta calidad es que solo es necesario usar un byte para su expresión, aunque se pierda precisión en la probabilidad de error.\\

Un recalibrador ajusta las calidades asignadas a cada lectura en un fichero \textit{BAM} para que sean más cercanas a la probabilidad de error real, teniendo en cuenta todas las lecturas del fichero y comparando si difieren del ADN de referencia.\\

Por ejemplo, si tenemos un fichero, aún no recalibrado, donde todas sus bases tienen calidad 25 y nos encontramos al recalibrar que 1 de cada 100 lecturas difieren del ADN referencia, entonces su calidad sería 20 y se ajustarían las calidades teniendo esto en cuenta. Pero el recalibrador tiene en cuenta más cosas, como que las lecturas de los últimos ciclos del secuenciador presentan más errores que las primeras, o las combinaciones de dos nucleótidos en las lecturas (contexto de dinucleótido).\\

\subsection{Formato \textit{BAM/SAM}}
\label{sec:bam}

\section{Búsqueda de información}

\section{Elección de tecnologías}

Una de las decisiones a tomar al comenzar el trabajo consistía en elegir el lenguaje de programación. El software de referencia, \textit{GATK}, utiliza Java \cite{javaweb}. Este lenguaje es ampliamente utilizado en el desarrollo de aplicaciones web y de servicios debido a su facilidad de uso, además de tener una curva de aprendizaje rápida. Es un lenguaje orientado a objetos e interpretado, lo cual permite su ejecución en distintas plataformas sin necesidad de recompilar. Su gestión de la memoria es automática.\\

Se desechó Java puesto que es interpretado por su máquina virtual (\textit{JVM} \textit{Java Virtual Machine}), lo cual produce una sobrecarga en el ejecución que no compensa su portabilidad. Además su gestión automática de memoria es también un inconveniente en sistemas donde el uso de la memoria es crítico para el rendimiento.\\

Se opto finalmente por utilizar C, puesto que es un lenguaje que te permite hacer cualquier cosa, aunque no sea tan fácil como java. La otra variante, C++, se desechó puesto que no necesitamos un enfoque orientado a objetos. C te permite un control total sobre la memoria y sus datos, lo cual permite optimizar el código para que se ajuste al sistema de memoria donde se alojará y utilizar estructuras de datos óptimas, con la consecuente ganancia en rendimiento. Además el código en C es compilado y optimizado por el propio compilador. Permite fácilmente la inclusión de código en ensamblador, lo cual puede ser un punto crítico en la ejecución de algunas operaciones básicas ejecutadas masivamente en el código. Como ventaja final, existe una amplia variedad de librerías para este lenguaje, depuradas y optimizadas durante años que facilitan bastante la programación sin sacrificar rendimiento.\\

Para este trabajo se incorporó el uso de las instrucciones \textit{SSE} \cite{ssemanual}, puesto que el compilador de C proporciona las funciones optimizadas para su uso, y en caso de no existir esas funciones, se pueden utilizar las instrucciones \textit{SSE} directamente en ensamblador (puesto que C lo permite). El uso de \textit{SSE}, en las partes del código que lo permitían, aumentaron el rendimiento como se verá más adelante.\\

\section{Diseño del software}

\section{Herramientas utilizadas}

Para el desarrollo del recalibrador se utilizaron varios tipos de herramientas, tanto para la edición del código como para su depurado. A continuación serán descritas.\\

\subsection{Editor de código y compilación}

\textit{Geany} \cite{geanyweb} es un editor de texto con algunas funciones de los entornos de desarrollo integrados (\textit{IDEs}). Es sencillo y rápido, ofreciendo una forma simple de manejar los ficheros de un proyecto. Puesto que lo he utilizado sólo para editar el código, no me han sido necesarias funciones adicionales de otros \textit{IDEs} o de compilación.\\

Para compilar el código he utilizado \textit{Makefile}, el cual es ampliamente utilizado para la compilación automática, usando ficheros de texto. Lo he utilizado sin herramientas de compilación adicionales, pero existen otras herramientas que generan automáticamente los \textit{Makefiles} y los actualizan sin necesidad de que el programador intervenga. Un ejemplo de estas herramientas es el \textit{GNU build system} o \textit{Autotools} \cite{autotoolsweb}. \textit{Autotools} será tenido en cuenta para trabajo futuro, además de otra herramienta llamada \textit{Scons} \cite{sconsweb} basada en scripts de \textit{Phyton}.\\

\subsection{Control de versiones}

Para el control de versiones del código se ha utilizado \textit{Git} \cite{gitweb}, esto me permite guardar la historia de cambios que ha sufrido el programa durante su desarrollo y permite revertir cambios para recuperar versiones anteriores. Ofrece un control de versiones distribuido, al contrario que otras herramientas como \textit{Subversion} \cite{subversionweb}, por lo que puedes trabajar en local y cuando sea posible combinar los cambios con el repositorio global. La razón de elegir \textit{Git} fue su facilidad de uso, por ejemplo a la hora de crear y combinar distintos flujos de trabajo.\\

La forma de trabajar con \textit{Git} que he seguido consiste en tener un flujo de trabajo llamado \textit{master} donde se recogen las características ya implementadas en el programa. A la hora de añadir una nueva funcionalidad al programa, creo un nuevo flujo de trabajo y realizo los cambios sobre el mismo. Cuando esa funcionalidad está añadida, combino ese flujo de trabajo con el \textit{master} obteniendo el programa con la característica implementada en ese flujo principal. Esto me permite trabajar en varías funcionalidades de forma separada, a la vez y sin interferir unas sobre otras, lo cual facilita el manejo del código.\\

\subsection{Depuración}

\textit{GDB} \cite{gdbweb} (\textit{GNU} debugger) es un depurador de código en línea de comandos. Entre otras cosas te permite comenzar la ejecución de un programa e incluir puntos de ruptura. En caso de que el programa termine su ejecución de forma anormal, te permite ver el estado de las variables y la pila de programa justo en el momento del error. Mayoritariamente he usado este programa para encontrar el origen de los fallos de segmentación que me he encontrado durante el desarrollo del recalibrador. Cuando ocurre un fallo de segmentación el propio sistema operativo vuelca el contenido de la memoria en ese momento en un fichero. \textit{GDB} permite restaurar la ejecución al momento del fallo usando ese fichero y ofreciendo una visión del estado del programa en ese momento.\\

El otro programa que he utilizado para depuración es \textit{Valgrind} \cite{valgrindweb}. Es un co njunto de herramientas de depuración que permiten detectar automáticamente muchos fallos en el manejo de memoria e hilos, permitiendo analizar los programas en detalle.\\

Durante el desarrollo del recalibrador he utilizado la herramienta \textit{memcheck} de \textit{Valgrind}. Esta herramienta permite detectar errores en la memoria, como accesos no válidos, uso de variables no inicializadas, liberación incorrecta de memoria reservada, fugas de memoria\ldots El principal uso que le he dado ha sido localizar puntos del código del recalibrador donde no se liberaba bien la memoria, provocando que la memoria se llene y disminuyendo el rendimiento de forma drástica.\\

\section{Algoritmo de recalibrado}

El algoritmo de recalibrado usado se compone de dos fases. La primera fase consiste en recopilar datos sobre los ficheros \textit{BAM}. La segunda fase es la recalibración en sí, se utilizan los datos obtenidos en la primera fase para ajustar las calidades de \textit{BAM} usando fórmulas estadísticas. A continuación se describe el proceso formal de recalibrado y cómo se realizan las dos fases en el algoritmo.\\

\subsection{Proceso formal de recalibrado}

formulas

\begin{equation}
\label{for:calidadsanger}
Q_{sanger}(p) = -10*\log_{10}(p)
\end{equation}

\begin{equation}
\label{for:probsanger}
P_{sanger}(q) = 10^\frac{-q}{10}
\end{equation}

\begin{equation}
\label{for:tasafallo}
T = \frac{\textit{número de fallos}}{\textit{número de bases}}
\end{equation}

\begin{equation}
\label{for:qualrecal}
Q^*(r,c,d) = Q(r) + \Delta Q + \Delta Q(r) + \Delta Q(r,c) + \Delta Q(r,d)
\end{equation}

\begin{equation}
\label{for:deltag}
\Delta Q = Q_{sanger}(T_g) - Q_{sanger}\left(\frac{\sum\limits_{r} P_{sanger}(Q(r))*\textit{número bases r}}{\textit{número bases global}}\right)
\end{equation}

\begin{equation}
\label{for:deltar}
\Delta Q(r) = Q_{sanger}(T(r)) - Q(r) - \Delta Q
\end{equation}

\begin{equation}
\label{for:deltarc}
\Delta Q(r,c) = Q_{sanger}(T(r,c)) - Q(r) - (\Delta Q + \Delta Q(r))
\end{equation}

\begin{equation}
\label{for:deltard}
\Delta Q(r,d) = Q_{sanger}(T(r,d)) - Q(r) - (\Delta Q + \Delta Q(r))
\end{equation}

\subsection{Fase 1: Recogida de datos}

En esta fase se lleva a cabo una recogida de datos sobre el fichero \textit{BAM} que se quiere analizar. Como ya se explicó en la sección \ref{sec:bam}, un fichero \textit{BAM} contiene un conjunto de lecturas de \textit{ADN}. Lo que se pretende es contabilizar la tasa de fallos de las lecturas de \textit{BAM} respecto al \textit{ADN} de referencia. La tasa de fallos se obtiene mediante la expresión de la fórmula \ref{for:tasafallo}. Es por ello que hay que contabilizar tanto los fallos que se han producido como las bases que se han leido.\\

Para ello el \textit{BAM} de entrada se procesa por lotes, es decir, se lee un conjunto de lecturas del fichero y se procesan. Inicialmente esto se hace de forma secuencial, leyendo un lote y procesándolo. Cuando se termina de procesar este lote se lee el siguiente. La forma de leer los lotes es secuencialmente, estos se leen de forma ordenada (de principio a fin) en el fichero \textit{BAM} usando la librería \textit{samtools}.\\

El procesado de cada lote consiste en leer por orden las lecturas que contiene. Cada una de estas lecturas tiene una secuencia de bases (nucleótidos) en forma de cadena de caracteres, indicando además qué posición de inicio representan en el \textit{ADN} de referencia. Lo que se hace para cada lectura es leer el \textit{ADN} de referencia en la misma posición y la misma longitud, obteniendo la cadena de caracteres del \textit{ADN} de referencia. La lectura de la cadena de referencia se realiza a través de \textit{samtools}.\\

Una vez se tiene una lectura, con \textit{N} bases, y su secuencia correspondiente en el \textit{ADN} de referencia, se comparan entre sí. La comparación se realiza base a base, es decir, la base de la lectura en la posición $x$ se compara con la base en la posición $x$ de la referencia. Si las bases no son iguales se contabiliza como un fallo.\\

Como son necesarias las tasas de fallo a distintos niveles, se contabilizan por separado en las estructuras de datos. La forma de contabilizar los fallos en una base consiste en utilizar la calidad asociada a esa base. Si es un fallo, se incrementa:
\begin{itemize}
\item
El contador de fallos y de lecturas global ($T_g$),
\item
el contador de fallos y de lecturas para el valor de esa calidad ($T(r)$),
\item
el contador de fallos y de lecturas para el par calidad-ciclo ($T(r,c)$) y
\item
el contador de fallos y de lecturas para el par calidad-dinucleótido ($T(r,d)$).
\end{itemize}

En caso de que no sea fallo sólo se incrementarían los contadores de lecturas correspondientes.\\

Una vez se han recorrido y contabilizado todas las lecturas del \textit{BAM} de entrada, se calculan las tasas de fallos en los diferentes niveles usando los contadores de fallos y lecturas correspondientes. Con estas tasas de fallos se calculan los deltas correspondientes. Finalmente tendremos en las estructuras de datos, el delta global ($\Delta Q$), el delta para cada valor de calidad ($\Delta Q(r)$), el delta para cada par calidad-ciclo ($\Delta Q(r,c)$) y el delta para cada par calidad-dinucleótido ($\Delta Q(r,d)$).\\

Para incrementar el rendimiento de esta fase, se han utilizado instrucciones \textit{SSE/SEE2}, concretamente para realizar las comparaciones de bases entre la secuencia de la lectura y la secuencia de referencia. Estas dos secuencias se almacenan de forma continua en memoria (vector de tipos \textit{char} o enteros de un byte).\\

Lo que se hace pues, en cada iteración, es cargar en un registro \textit{XMM} de 128 bits (utilizados por las instrucciones SSE) 16 bases del vector de la secuencia leída, utilizando una sola lectura de memoria. En otro registro \textit{XMM} se cargan las 16 bases correspondientes al vector de referencia, mediante otra lectura de memoria. Acto seguido se usa la instrucción de comparación de \textit{SSE2} sobre las 16 bases, obteniendo en un registro \textit{XMM} los resultados de las comparaciones (\textit{0}x\textit{FF} si es igual o \textit{0}x\textit{00} si no). Finalmente se guardan en una variable vector los resultados de las 16 comparaciones con otra instrucción de memoria.\\

Como efecto resultante al usar \textit{SSE}, los vectores se recorren de 16 en 16 elementos. Si no usamos \textit{SSE} los elementos se recorrerían de 1 en 1. Esto tiene un gran impacto en el rendimiento como se verá en la sección \ref{sec:evaluacion}.\\

\subsection{Fase 2: Recalibrado}

En esta fase se lleva a cabo el proceso de recalibrado en sí. Al igual que en la fase anterior, el fichero \textit{BAM} de entrada se procesa por lotes. El fichero \textit{BAM} con las calidades recalibradas que se genera, se escribe por lotes conforme estos han sido procesados y en el mismo orden que se leyeron.\\

El procesado de cada lectura consiste en aplicar únicamente la fórmula \ref{for:qualrecal} a cada una de las calidades de sus bases, sustituyendo las mismas por los nuevos valores. Puesto que los deltas ya han sido calculados en la fase anterior, se pueden utilizar directamente en los cálculos accediendo a sus valores en las estructuras de datos. El valor final de las calidades es pues las cuatro sumas de los deltas correspondientes. Finalmente se genera el fichero \textit{BAM} con las nuevas calidades.\\

\subsection{Estructura de datos utilizadas}

\subsection{Parámetros de ejecución del recalibrador}

\section{Evaluación del recalibrador obtenido}
\label{sec:evaluacion}