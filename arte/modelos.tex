\section{Modelos de programación paralela}

En este apartado se presentarán los tres modelos principales de programación paralela que se utilizan, los cuales se distinguen en la forma que tienen los procesadores para comunicarse.\\

\subsection{Espacio de memoria compartido}

Este modelo de programación paralela se caracteriza por tener un espacio de memoria físicamente unido, común a todos los procesadores que intervienen en el sistema. La interacción se realiza mediante la modificación de los datos que residen en la memoria compartida. En la Figura \ref{fig:compartida} se muestra gráficamente el modelo de memoria compartida.\\

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{compartida.png}
\caption{Modelo paralelo de memoria compartida.\label{fig:compartida}}
\end{figure}

Hay dos tipos de memoria en las plataformas que implementan este sistema, la memoria local a un procesador y la memoria global a todos los procesadores. Si el tiempo de acceso a ambas memorias es idéntico, estamos antes un sistema de acceso a memoria uniforme (\textit{UMA}); si el tiempo de acceso es distinto, estamos ante un sistema de acceso a memoria no uniforme (\textit{NUMA}) puesto que dependiendo de la posición de memoria que se acceda y su lejanía del nodo que la accede, el tiempo de acceso varía. Un ejemplo de sistema \textit{UMA} es un sistema multiprocesador simétrico o \textit{SMP}, en cambio, un sistema multiprocesador escalable de memoria compartida pertenece al tipo \textit{NUMA}.\\

Este modelo hace que la programación sea mucho más fácil, puesto que las lecturas de memoria son transparentes al programador, siendo necesario únicamente una mayor complejidad en las operaciones de lectura/escritura. Esto es debido a que se hacen necesarios mecanismos de bloqueos sobre variables o \textit{locks} para evitar el acceso simultáneo de varios procesadores a los mismos datos (exclusión mutua).\\

Puesto que las arquitecturas actuales incorporan el uso de memorias caché en los procesadores, se hace necesaria la implementación de sistemas de coherencia de caché en estos sistemas, lo cual aumenta la complejidad hardware de estas arquitecturas. Los sistemas \textit{NUMA} se dividen en dos tipos dependiendo del sistema de coherencia que implementan, los \textit{CC-NUMA} mantienen la coherencia en todas las caches, mientras que los \textit{NCC-NUMA} no.\\

Algunos paradigmas de programación utilizados en el modelo de espacio de memoria compartido son los threads (como por ejemplo \textit{Pthreads}), directivas (OpenMP) y uso de GPUs (por ejemplo CUDA).\\

Los POSIX \cite{advunix} (\textit{Portable Operating System Interface uniX}) \textit{threads} (a partir de ahora \textit{pthreads}) se basan en el concepto de hilo o \textit{thread}, que la mayoría de sistemas operativos actuales utiliza.\\

En un sistema UNIX, un proceso no es más que un único hilo de control. Este hilo podría replicarse para crear más hilos ``hijos'', permitiendo que cada uno de estos hilos se dedique a ejecutar una tarea distinta a los demás. Esto permite no solo ejecutar un programa con varios hilos ejecutándose en paralelo, sino que permite abstraer el programa en ta\-reas definidas, independientemente del número de procesadores que tengamos. Estos hilos también comparten memoria, por lo que se enmarca dentro del modelo de memoria compartida.\\

\textit{Pthreads} \cite{advunix} es la interfaz de programación con hilos que ofrecen las librerías POSIX. Esta interfaz nos ofrece funciones simples y potentes necesarias para crear cualquier código que utilice hilos.\\

Por otro lado, \textit{OpenMP} \cite{openmpquinn,openmpchandra,openmpreview} es un API de programación paralela para multiprocesadores de memoria compartida (basada en directivas del compilador, rutinas de librería y variables de entorno), en C/C++ y Fortran. Puede ejecutarse en sistemas Unix y Windows. Sus características más importantes residen en su simplicidad y flexibilidad, ofreciendo una interfaz que permite crear programas paralelos tanto para sistemas sobremesa como supercomputadores.\\

\textit{OpenMP} basa su funcionamiento en el modelo \textit{fork-join} (Figura \ref{fig:forkjoin}) para llevar a cabo las tareas paralelas. Además se asegura una ejecución correcta tanto en sistemas paralelos como secuenciales (siempre y cuando sea correctamente utilizado). Por otra parte, utiliza el modelo de memoria compartida para ejecutar sus hilos. Permite que los hilos compartan espacio de memoria, pero también permite que tengan su propio espacio de memoria privada. Además permite a los hilos obtener una instantánea del estado de la memoria o \textit{snapshot} en cualquier momento, y utilizar esa información mientras el resto de hilos pueden seguir modificando la memoria sin afectar al \textit{snapshot}.\\

\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{forkjoin.png}
\caption{Modelo paralelo \textit{Fork-Join} usado por \textit{OpenMP}\cite{openmpchandra}.\label{fig:forkjoin}}
\end{figure}

Otro API de programación utilizado para plataformas de memoria compartida basadas en GPU es \textit{CUDA}\cite{progparmachines}. Las GPUs son máquinas SIMD según la taxonomía de Flynn (véase Sección \ref{sec:flynn}) que utilizan el modelo de memoria compartida. Una diferencia con los procesadores con varios núcleos de procesamiento o \textit{multicores}, que también utilizan este modelo, es que las GPUs pueden tener miles de hilos ejecutandose simultáneamente. Un programa en CUDA tiene dos partes: el código que se ejecuta en el \textit{host} o procesador central (CPU), y el código, llamado \textit{kernel}, que se ejecuta en el \textit{device} (GPU). Debido a esto es necesaria una CPU que trabaje en conjunto con la GPU. Cualquier aplicación que pueda explotar el modelo SIMD, donde se apliquen las mismas instrucciones a un conjunto de datos, se verá muy beneficiada en el uso de una GPU. Cualquier otro tipo de aplicación no es factible en estas plataformas.\\

Otro ejemplo de sistema de memoria compartida son las instrucciones \textit{SSE} \cite{ssemanual} (\textit{Streaming SIMD Extensions}), consisten en un conjunto de instrucciones máquina del procesador junto con determinado hardware asociado. Se basa en un modelo \textit{SIMD} debido a que es un procesamiento vectorial donde se aplica una misma instrucción a varios datos de forma simultánea en el tiempo. Por tanto, con estas instrucciones podremos realizar en paralelo la misma operación sobre varios datos al mismo tiempo.\\

\subsection{Paso de mensajes}

En este modelo, la plataforma consiste en una serie de nodos de procesamiento interconectados, cada uno con su propio espacio de direcciones de memoria. Cada nodo puede ser un solo procesador o un multiprocesador con espacio de memoria compartido entre sus núcleos de procesamiento o \textit{cores}. En este modelo, la interacción entre procesos ejecutándose en distintos nodos se realiza mediante el paso de mensajes. En la Figura \ref{fig:distribuida} se puede ver una representación de un sistema que utilizaría paso de mensajes para la comunicación.\\

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{distribuida.png}
\caption{Modelo paralelo de paso de mensajes.\label{fig:distribuida}}
\end{figure}

Los mensajes proporcionan un modo de transferir datos, tareas y sincronizar procesos. Puesto que la interacción se consigue mediante envío/recepción de mensajes, las operaciones básicas de este paradigma de programación son \textit{send} y \textit{receive}. Es necesario además un mecanismo que asigne un identificador único (\textit{id}) a cada proceso que permita identificarlo en un programa paralelo con múltiples procesos, puesto que los mensajes necesitan un \textit{id} de destino para ser entregados. Un proceso podría saber pues su \textit{id} introduciendo la operación \textit{whoami}.\\

Otra función necesaria es \textit{numprocs} que diga al proceso el número de procesos que intervienen en el programa paralelo. Con las cuatro operaciones introducidas anteriormente se puede implementar cualquier programa de paso de mensajes. Algunas de las implementaciones de paso de mensaje más utilizadas son \textit{Message Passing Interface} \cite{progparmachines,openmpquinn,usingmpi} (\textit{MPI}) y \textit{Parallel Virtual Machine} \cite{pvmweb} (\textit{PVM}).\\ 

\textit{Message Passing Interface} es un estándar de facto para el modelo de programación paralela mediante paso de mensajes. MPI, al igual que OpenMP, es una API usada generalmente en entornos C/C++ entre otros. Se dispone de implementaciones tanto en código libre, como propietarias. Entre las implementaciones más conocidas se encuentran \textit{OpenMPI} \cite{openmpiweb}, \textit{LAM} \cite{burns94lam} (\textit{Local Area Multicomputer}) y \textit{MPICH} \cite{usingmpi} (\textit{MPI over CHameleon}).\\

La forma de procesar un programa, en un entorno MPI, consiste en ejecutar copias de ese programa (procesos) en tantas máquinas como se quieran utilizar. Cada copia se encarga de procesar una parte de los datos de entrada intercambiando información, mediante paso de mensajes, por la red. MPI permite distintas clases de comunicación en los sistemas que la utilizan. En las comunicaciones colectivas interviene un nodo que interactúa con los demás, ya sea que todos le manden información al mismo o que éste envíe información a todos. También permite las comunicaciones punto a punto. Además, estas dos clases de comunicación tienen dos variantes: bloqueantes y no bloqueantes.\\

Adicionalmente, existe una API basada en MPI para operaciones I/O en sistemas paralelos de almacenamiento, se llama \textit{MPI-IO} \cite{usingmpi}. Esta API es la parte de MPI que maneja el I/O ofreciendo distintas operaciones de lectura y escritura. Permite además determinar cómo se van a distribuir los datos entre los procesos, y cómo se van a almacenar los datos en disco una vez procesados. Esto permite solucionar las limitaciones de memoria al procesar ficheros muy grandes (no hay que cargarlos en la memoria de una sola máquina) y obtener un único fichero de salida.\\

\subsection{Partitioned Global Address Space - PGAS}

El modelo de PGAS \cite{intropgas} se caracteriza por ofrecer al programador un espacio de memoria único y compartido en un sistema con memoria distribuida. Mediante una capa interfaz, se ofrece a los nodos (que tiene cada uno su memoria local) una forma de utilizar también las memorias locales de los otros nodos del sistema. Lo que esto ofrece al programador es una visión local de todo el espacio de memoria como uno único y global, transparencia en las comunicaciones (puesto que el compilador se encarga de las mismas) y soporte para datos distribuidos. En la Figura \ref{fig:pgas} se muestra una posible solución de un modelo PGAS.\\

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{pgas.png}
\caption{Modelo paralelo PGAS.\label{fig:pgas}}
\end{figure}

A nivel de nodo, la variables de memoria pueden ser \textit{shared} o \textit{local}, permitiendo compartir únicamente las variables que interesan para la comunicación y no sobrecargando la comunicación con variables auxiliares y privadas que solo le sirven al nodo local. Algunos APIs de programación que utilizan este modelo son \textit{Unified Parallel C} \cite{upcweb}, \textit{Co-Array Fortran} \cite{cofortranweb}, \textit{Titanium} \cite{titaniumweb}, \textit{X10} \cite{x10web}, \textit{Chapel} \cite{chapelweb} y \textit{OmpSS} \cite{gpuompss}.\\

OmpSS es un modelo de programación que utiliza como base OpenMP (y puede considerarse una variante de PGAS), modificándolo para soportar paralelismo irregular, asíncrono y en plataformas heterogéneas. Utiliza un modelo de \textit{pool} de hilos en lugar de \textit{fork-join}(usado por OpenMP), donde un hilo maestro crea los trabajos y el resto de hilos los procesan. Otra diferencia es la distinción de varios espacios de memoria de cada nodo, al contrario del único espacio de memoria de OpenMP. Es el propio compilador el que se encarga de distribuir los datos y elegir en qué dispositivo procesarlos. Ofrece una visión de memoria compartida en un sistema distribuido al igual que los PGAS, con la diferencia de que cada nodo tiene adicionalmente su propio espacio de memoria.\\